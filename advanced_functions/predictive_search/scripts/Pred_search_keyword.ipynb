{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module for predicting top n best possible word matches given a word\n",
    "\n",
    "# Context:\n",
    "# A -> True word\n",
    "# B -> Typed word\n",
    "\n",
    "# Make dictionary, key (true word), value (list of incorrect words)\n",
    "# tru_in dict is A -> [B1,B2,...,Bn]\n",
    "missp_dat_path = \"/Users/daveistanto/Documents/project_normal/advanced_functions/predictive_search/dataset/missp.dat\"\n",
    "wiki_dat_path = \"/Users/daveistanto/Documents/project_normal/advanced_functions/predictive_search/dataset/wikipedia.dat\"\n",
    "aspell_dat_path = \"/Users/daveistanto/Documents/project_normal/advanced_functions/predictive_search/dataset/aspell.dat\"\n",
    "\n",
    "tru_in = dict()\n",
    "\n",
    "def add_to_dict(data_path, input_dict):\n",
    "    with open(data_path, 'r') as df:\n",
    "        data_lines = df.readlines()\n",
    "        for line in data_lines:\n",
    "            lns = line[:-1].upper()\n",
    "            if lns[0] == \"$\":     \n",
    "                curr_key = lns[1:]\n",
    "                if curr_key not in list(set(input_dict)):\n",
    "                    input_dict[curr_key] = []\n",
    "            else:\n",
    "                 input_dict[curr_key].append(lns)\n",
    "    \n",
    "    for k, v in input_dict.items():\n",
    "        tru_in[k] = list(set(tru_in[k]))\n",
    "    return input_dict\n",
    "\n",
    "tru_in = add_to_dict(missp_dat_path, tru_in)\n",
    "tru_in = add_to_dict(wiki_dat_path, tru_in)\n",
    "tru_in = add_to_dict(aspell_dat_path, tru_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store dictionary in json\n",
    "\n",
    "import json\n",
    "\n",
    "with open('../saved_states/tru_in.json', 'w') as fp:\n",
    "    json.dump(tru_in, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get P(A) distribution\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "word_freq_path = \"/Users/daveistanto/Documents/project_normal/advanced_functions/predictive_search/dataset/top_5k_words.csv\"\n",
    "word_freq_df = pd.read_csv(word_freq_path)\n",
    "\n",
    "def normalize_word(input_word):\n",
    "    input_word = input_word.upper()[3:]\n",
    "    return input_word\n",
    "\n",
    "normalize_word = np.vectorize(normalize_word)\n",
    "\n",
    "word_freq_df[\"Normalized word\"] = np.apply_along_axis(normalize_word, 0, word_freq_df[\"Word\"].values)\n",
    "word_freq_df = word_freq_df.drop(columns=[\"Word\"])\n",
    "word_freq_df[\"Relative Frequency\"] = 0\n",
    "\n",
    "# Add dummy frequency of 1000 if word not found\n",
    "for k in tru_in.keys():\n",
    "    if k.upper() not in word_freq_df[\"Normalized word\"].values:\n",
    "        new_row = {\"Frequency\": 1000, \"Normalized word\": k}\n",
    "        word_freq_df = word_freq_df.append(new_row, ignore_index=True)\n",
    "\n",
    "# Add relative frequency (P(A)) for each A\n",
    "word_sum = word_freq_df[\"Frequency\"].sum()\n",
    "for row_index in range(len(word_freq_df)):\n",
    "    word_freq_df.iloc[row_index, 2] = word_freq_df.iloc[row_index, 0] / word_sum\n",
    "    \n",
    "    \n",
    "# Sort word_freq_df by frequency\n",
    "word_freq_df = word_freq_df.sort_values(by=\"Frequency\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store word_freq_df in csv\n",
    "word_freq_df.to_csv('/Users/daveistanto/Documents/project_normal/advanced_functions/predictive_search/saved_states/word_freq_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word_freq_df and tru_in dictionary\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "word_freq_df = pd.read_csv(\"../saved_states/word_freq_df.csv\")\n",
    "\n",
    "with open('../saved_states/tru_in.json', 'r') as fp:\n",
    "    tru_in = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get P(B|A) distribution for specific B. Does not equal 1 because different A(s).\n",
    "\n",
    "def get_P_BA(B):\n",
    "    PBA_dict = dict()\n",
    "    B = B.upper()\n",
    "    for k, v in tru_in.items():\n",
    "        PBA_for_given_A = tru_in[k].count(B) / len(tru_in[k])\n",
    "        PBA_dict[k] = PBA_for_given_A\n",
    "        \n",
    "    return PBA_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get P(A) given specific A:\n",
    "\n",
    "def get_PA(A):\n",
    "    P_A = word_freq_df[\"Relative Frequency\"][word_freq_df[\"Normalized word\"] == A].values[0]\n",
    "    return P_A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARE', 'A', 'AND', 'I', 'OR', 'AREA', 'AIR', 'OUR', 'EYE', 'FIRE', 'ERE']\n"
     ]
    }
   ],
   "source": [
    "# Get relative P(A|B)\n",
    "\n",
    "def get_PAB(B):\n",
    "    B = B.upper()\n",
    "    PBA_dict = get_P_BA(B)\n",
    "    PAB_list = []\n",
    "    for k, v in PBA_dict.items():\n",
    "            if v != 0:\n",
    "                P_A = get_PA(k)\n",
    "                tup = (k, PBA_dict[k] * P_A)\n",
    "                PAB_list.append(tup)\n",
    "\n",
    "    PAB_list.append((B, 1))\n",
    "    \n",
    "    # Sort by value, descending\n",
    "    PAB_list.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    \n",
    "    #Get the words only\n",
    "    words_only = [i[0] for i in PAB_list]\n",
    "    \n",
    "    return words_only\n",
    "\n",
    "print(get_PAB(\"are\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-F']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(get_PAB(sys.argv[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
